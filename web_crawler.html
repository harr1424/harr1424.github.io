<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1" name="viewport">

    <link rel="stylesheet" href="style.css">

    <!-- Bootstrap CSS -->
    <link crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
        integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" rel="stylesheet">


    <title>Web Crawler</title>
</head>

<body>
    <div class="container">
        <div class="row ">
            <div class="dropdown">
                <a class="btn btn-secondary btn-lg dropdown-toggle" href="#" role="button" id="dropdownMenuLink"
                    data-bs-toggle="dropdown" aria-expanded="false">
                    Portfolio Contents
                </a>

                <ul class="dropdown-menu" aria-labelledby="dropdownMenuLink">
                    <li><a class="dropdown-item" href="index.html">Home</a></li>
                    <li>
                        <hr class="dropdown-divider">
                    </li>
                    <li><a class="dropdown-item" href="mobile_app_dev.html">Mobile Application Development</a></li>
                    <li><a class="dropdown-item" href="cloud_computing.html">Cloud Computing</a></li>
                    <li><a class="dropdown-item" href="3.html">Topic 3</a></li>
                    <li><a class="dropdown-item" href="4.html">Topic 4</a></li>
                    <li><a class="dropdown-item" href="5.html">Topic 5</a></li>
                    <li><a class="dropdown-item" href="reflective_essay.html">Reflective Essay</a></li>
                    <li><a class="dropdown-item" href="/files/CV.docx" download="CV_JohnHarrington">Cirriculum Vitae</a></li>
                    <li>
                        <hr class="dropdown-divider">
                        <li><a class="dropdown-item" href="orange_weather.html">iOS Networking - Orange Weather</a></li>
                        <li><a class="dropdown-item" href="list_maker.html">iOS Data Persistence - List Maker</a></li>
                        <li><a class="dropdown-item" href="koradi_app.html">Fultter Radio App</a></li>
                        <li><a class="dropdown-item" href="twitter_bot.html">Twitter Air Quality Bot</a></li>
                        <li><a class="dropdown-item" href="web_crawler.html">Python Web Crawler</a></li>


                    </li>

                </ul>
            </div>
        </div>
        <div class="pt-5"></div>
        <div class="row">
            <div class="col-md-6">
                <h3>
                    <a href="https://github.com/harr1424/web_crawler">Web Crawler</a>
                </h3>
                <ul>
                    <li>
                        This python script was written to crawl a website in order to find any anchor tags that
                        link to <code>.zip</code> file downloads. The addresses of these files is stored in a list and
                        once
                        crawling is completed the script will download each file using the <code>requests</code> module.
                    </li>
                    <li>
                        The program user must specify a url to crael as well as where on their local machine that they
                        wish to store downloaded files.
                    </li>
                    <li>
                        Many sites block requests from clients that do not provide a user agent string in the reguest
                        header. For this
                        reason I have specified a user agent agent representing a commonly used web browser.
                    </li>
                    <li>
                        The <code>crawl()</code> function reguests the html content of a web page and uses the
                        <code>BeautifulSoup</code>
                        module to parse out each anchor tag's <code>href</code> attribute.
                    </li>
                    <li>
                        <code>BeautifulSoup</code> has a <code>find</code> method which accepts a regular expression as
                        an arguemnt.
                        Here this is used to find all anchor tag <code>href</code> attributes containing any pattern
                        typical of
                        a english page on this particular site: an <code>/en</code> subdirectory followed by any number
                        of any characters.
                    </li>
                    <li>
                        These links are stored in a list named <code>authors</code>.
                    </li>
                    <li>
                        The <code>authors</code> list is then subsequently crawled for any anchor tages with
                        <code>href</code> attributes
                        containing a <code>.zip</code> file extension.
                    </li>
                    <li>
                        These links are then stored in a list named <code>target_links</code>.
                    </li>
                    <li>
                        <a href="https://github.com/tqdm/tqdm">TQDM</a> is a module that provides a graphical
                        represention of the
                        program's process. It can be used by simply wrapping any sort of iterable in it's invocation as
                        follows:
                        <code>
                            <pre>
for each in tqdm(some_list):
    # do something
                            </pre>
                        </code>
                    </li>
                    <li>
                        The <code>download()</code> function accepts as a single parameter a list of urls to download.
                        In this case, it is the list of all <code>.zip</code> files found on all english subdirectories
                        of
                        the target website.
                    </li>
                    <li>
                        The url for each file download is used to create a filename used to save the download onto the
                        program usr's local machine.
                    </li>
                    <li>
                        The program user must have specified a path at which to save all downloads at the top of the
                        script.
                        If this path does not exist, it will be created.
                    </li>
                    <li>
                        If the file does not already exist at the specified path, it will be downloaded. Because most
                        files available for download on the internet are of considerable size, the files are broken into
                        1024MB chunks as they are downloaded and written to disk incrementally instead of attempting to
                        write the entire file to disk at once.
                    </li>
                    <li>
                        As this process can take a significant amount of time, <code>TQDM</code> has again been used in
                        order to provide the
                        program user with a progress view.
                    </li>
                </ul>
            </div>
            <div class="col-md-6">
                <pre>
                <code>
import requests
import re
import os
from bs4 import BeautifulSoup
from tqdm import tqdm

# The site you wish to crawl for downloads
target_url = "target_url"

# The location on your local machine to save downloads
parent_dir = "/Users/user/" 

# Some sites block requests if a user agent string is not providded
headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:94.0) Gecko/20100101 Firefox/94.0',
}


"""
Crawls a web page and stores anchor tag href attributes in a list for subsequent download
"""
def crawl():
    target_links = []
    print("Crawling Main Page")
    response = requests.get(target_url, headers=headers)
    soup = BeautifulSoup(response.content, 'html5lib')
    indirect_links = soup.find_all('a', {'href': re.compile(r'/en.*-.*/')})
    authors = [link['href'] for link in indirect_links]
    print("Crawling Secondary Pages")
    for each in tqdm(authors):
        response = requests.get(each, headers=headers)
        soup = BeautifulSoup(response.content, 'html5lib')
        download_links = soup.find_all('a', {'href': re.compile(r'.*.zip')})
        for link in download_links:
            target_links.append(link['href'])
    target_links = list(set(target_links))
    print(len(target_links), "Files available for download...")
    return target_links


def download(target_links):
    print("Beginning Downloads...")
    for link in target_links:
        author = link.split('/')[-2]
        file_name = link.split('/')[-1]
        dir_path = os.path.join(parent_dir, author)
        if not os.path.exists(dir_path):
            os.mkdir(dir_path)
        file_path = os.path.join(dir_path, file_name)
        if not os.path.isfile(file_path):
            print("Downloading file:%s from %s" % (file_name, author))
            response = requests.get(link, stream=True)
            with open(file_path, "wb+") as f:
                for chunk in tqdm(response.iter_content(chunk_size=1024 * 1024)):
                    if chunk:
                        f.write(chunk)
            print("%s downloaded!\n" % file_name)
    print("All files downloaded!")
    return


if __name__ == "__main__":
    links = crawl()
    download(links)
                </code>
        </pre>
            </div>
        </div>
    </div>
    <div style="text-align: center">
        <h3> <a href="#">Top Of Page</a> </h3>
    </div>
    <!-- Option 1: Bootstrap Bundle with Popper -->
    <script crossorigin="anonymous" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
        src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
</body>

</html>